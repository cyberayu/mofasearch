# Deep-Inquire Research Agent System

A multi-node research analysis system based on the Dora framework, integrated with the OpenAI streaming API service.

## System Architecture Diagram
```mermaid
graph LR
    Client[Client] -->|HTTP Request| Server[[dora-openai-server]]
    Server -->|User Query| Agent[[deep-inquire-agent]]
    Agent -->|Research Result| Server
    Server -->|Streaming Response| Client
```

## Node Functionality Description

### 1. dora-openai-server Node
- **Path**: `../../node-hub/openai-server-stream`
- **Functionality**:
  - Provides an HTTP endpoint that complies with the OpenAI API specifications.
  - Handles client streaming requests/responses.
  - Forwards user queries to the research agent.
  - Returns research snippets generated by the agent in real time.
- **Inputs and Outputs**:
  ```yaml
  inputs: deep-inquire-agent/deep_inquire_result
  outputs: v3/chat/completions
  ```

### 2. deep-inquire-agent Node
- **Path**: `../../agent-hub/deep-inquire`
- **Functionality**:
  - Executes a multi-stage research analysis:
    1. Intelligent web search (using the Serper API)
    2. Context extraction and credibility evaluation
    3. Contradiction detection and synthesis generation
  - Generates real-time research snippets along with a final report.
- **Inputs and Outputs**:
  ```yaml
  inputs: dora-openai-server/v3/chat/completions
  outputs: deep_inquire_result
  ```

## Environment Configuration

1. Configure the secret key file (already pre-configured)
```bash
# .env.secret already contains:
LLM_API_KEY=
LLM_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
LLM_MODEL_NAME=deepseek-v3-241226
SERPER_API_KEY=
```

## Startup Process

```bash
# Execute in the directory python/examples/deep-inquire/

# Clean up the environment
dora destroy

# Start the Dora service
dora up

# Build the dataflow nodes
dora build deep-inquire-dataflow.yml

# Start and monitor the dataflow
dora start deep-inquire-dataflow.yml --attach
```

## Testing Methods

### Using the Test Client
```bash
python moly_client_stream.py
```

### Example Request/Response
```python
# Example request
user_input = 'Latest research on security protection for large language models'

# Example response snippet
{
  "type": "thinking",
  "content": "Analyzing 3 papers from arXiv...",
  "articles": [
    {
      "title": "New Method for LLM Adversarial Training",
      "url": "https://arxiv.org/abs/2405.12345",
      "relevance": 0.95
    }
  ]
}
```