import json
import os
from mofa.agent_build.base.base_agent import MofaAgent, run_agent
from mofa.utils.ai.conn import generate_json_from_llm, structor_llm
from mofa.utils.files.read import read_yaml
from agent_config_generator import agent_config_dir_path
from pydantic import BaseModel, Field
from typing import Optional
import datetime
from mofa.utils.files.dir import make_dir
from mofa.utils.files.write import write_file


class LLMGeneratedConfig(BaseModel):
    """
    Represents different types of content generated by LLM,
    including configuration, code, and documentation.
    """
    # Configuration content

    agent_name: str = Field(
        ...,
        description="The name of the agent."
    )
    module_name: str = Field(
        ...,
        description="The name of the module."
    )

class LLMGeneratedContent(BaseModel):
    """
    Represents different types of content generated by LLM,
    including configuration, code, and documentation.
    """
    # Configuration content
    env_config: Optional[str] = Field(
        None,
        description="Generated .env configuration content containing sensitive keys and environment variables"
    )
    
    yml_config: Optional[str] = Field(
        None,
        description="Generated YAML configuration content for non-sensitive settings and parameters"
    )


def generate_agent_config(user_query:str,agent_config_path:str,env_file_path:str,response_model:object,prompt_selection:str='prompt',add_prompt:str=None):
    agent_config = read_yaml(
        file_path=agent_config_path
    )
    sys_prompt = agent_config.get('agent', {}).get(prompt_selection, '')
    messages = [
        {
            "role": "system",
            "content": sys_prompt
        },
        {
            "role": "user",
            "content": user_query if add_prompt is None else f"{user_query}  {add_prompt}"
        }
    ]
    response = structor_llm(env_file=env_file_path, messages=messages, prompt=user_query,response_model=response_model)
    return response

@run_agent
def run(agent: MofaAgent):
    env_file_path = os.path.join(agent_config_dir_path, '.env.secret')
    agent_config_path = os.path.join(agent_config_dir_path, 'configs', 'agent.yml')
    user_query = agent.receive_parameter('query')
    print('time : ',datetime.datetime.now().strftime("%H:%M:%S"))
    config_result = generate_agent_config(response_model=LLMGeneratedConfig, user_query=user_query, agent_config_path=agent_config_path, env_file_path=env_file_path,prompt_selection='agent_name_gen_prompt ')
    agent_name = config_result.agent_name.replace(' ','-').replace('_','-').replace('  ','-')
    module_name,module_path = config_result.module_name.replace(' ','_').replace('  ','_').lower(),f"{agent_name}/{config_result.module_name}"
    make_dir(f"{agent_name}/{module_name}/configs")
    print('config_result : ',config_result.json())
    result = generate_agent_config(response_model=LLMGeneratedContent, user_query=user_query, agent_config_path=agent_config_path, env_file_path=env_file_path,add_prompt=f"agent_name: {agent_name} module_name: {module_name}")
    print('agent_result: ',result.json())
    write_file(data=result.yml_config, file_path=f"{module_path}/configs/agent.yml")
    write_file(data=result.env_config, file_path=f"{module_path}/.env.secret")
    result = json.loads(result.json())
    print(result)
    result['agent_name'] = agent_name
    result['module_name'] = module_name
    print('result : ',result)
    agent.send_output(agent_output_name='config_generator_result', agent_result=result)

def main():
    agent = MofaAgent(agent_name='agent_config_generator')
    run(agent=agent)

if __name__ == "__main__":
    main()
